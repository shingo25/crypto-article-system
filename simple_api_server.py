#!/usr/bin/env python3
"""
FastAPI server with complete authentication system
"""

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import os
import sys
import logging
from datetime import datetime

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), 'src')))

# è¨­å®šã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from src.config import Config
    from src.cors_config import CORSConfig
    config_available = True
except ImportError:
    logger.warning("è¨­å®šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    config_available = False

# èªè¨¼é–¢é€£ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from src.auth_routes import router as auth_router
    from src.database import engine, Base, create_tables, get_db
    from src import auth_models
    auth_available = True
except ImportError as e:
    logger.warning(f"èªè¨¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
    auth_available = False

# ãƒˆãƒ”ãƒƒã‚¯ç”Ÿæˆé–¢é€£ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from src.topic_generator import generate_topics_from_market_data
    topic_generator_available = True
    logger.info("ãƒˆãƒ”ãƒƒã‚¯ç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
except ImportError as e:
    logger.warning(f"ãƒˆãƒ”ãƒƒã‚¯ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
    topic_generator_available = False

# RSSã‚½ãƒ¼ã‚¹ç®¡ç†é–¢é€£ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from src.rss_routes import router as rss_router
    rss_routes_available = True
    logger.info("RSSã‚½ãƒ¼ã‚¹ç®¡ç†ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
except ImportError as e:
    logger.warning(f"RSSãƒ«ãƒ¼ã‚¿ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
    rss_routes_available = False

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆï¼ˆèªè¨¼æ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
if auth_available:
    try:
        logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆä¸­...")
        create_tables()
        logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆã«å¤±æ•—: {e}")

# FastAPI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
app = FastAPI(
    title="Crypto Article Generation System API",
    description="æš—å·é€šè²¨è¨˜äº‹è‡ªå‹•ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®REST API",
    version="1.0.0"
)

# CORSè¨­å®š
if config_available:
    cors_config = CORSConfig.get_cors_config()
    logger.info(f"Using environment-specific CORS config: {cors_config['allow_origins']}")
else:
    cors_config = {
        "allow_origins": ["http://localhost:3000", "http://127.0.0.1:3000", "http://localhost:3001", "http://127.0.0.1:3001"],
        "allow_credentials": True,
        "allow_methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
        "allow_headers": ["*"],
        "expose_headers": ["*"]
    }
    logger.info("Using default CORS config")

app.add_middleware(CORSMiddleware, **cors_config)

# ãƒˆãƒ”ãƒƒã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”¨ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
topic_cache = []
last_topic_update = None

# èªè¨¼ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚’ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ãƒ‰ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
if auth_available:
    app.include_router(auth_router, prefix="/api")
    logger.info("èªè¨¼ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚’è¿½åŠ ã—ã¾ã—ãŸ: /api/auth/*")

# RSSã‚½ãƒ¼ã‚¹ç®¡ç†ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚’ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ãƒ‰ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
if rss_routes_available:
    app.include_router(rss_router, prefix="/api")
    logger.info("RSSã‚½ãƒ¼ã‚¹ç®¡ç†ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚’è¿½åŠ ã—ã¾ã—ãŸ: /api/rss-sources/*")

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã®å‡¦ç†
@app.on_event("startup")
async def startup_event():
    """ã‚µãƒ¼ãƒãƒ¼èµ·å‹•æ™‚ã«ãƒˆãƒ”ãƒƒã‚¯ã‚’ç”Ÿæˆ"""
    global topic_cache, last_topic_update
    
    if topic_generator_available:
        try:
            logger.info("åˆæœŸãƒˆãƒ”ãƒƒã‚¯ç”Ÿæˆã‚’é–‹å§‹...")
            # DBã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¦ãƒˆãƒ”ãƒƒã‚¯ç”Ÿæˆã«æ¸¡ã™
            db_session = next(get_db()) if auth_available else None
            topics = generate_topics_from_market_data(db_session)
            if db_session:
                db_session.close()
            topic_cache = topics
            last_topic_update = datetime.now()
            logger.info(f"åˆæœŸãƒˆãƒ”ãƒƒã‚¯ç”Ÿæˆå®Œäº†: {len(topics)}ä»¶ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
        except Exception as e:
            logger.error(f"åˆæœŸãƒˆãƒ”ãƒƒã‚¯ç”Ÿæˆã«å¤±æ•—: {e}", exc_info=True)
            topic_cache = []
    else:
        logger.warning("ãƒˆãƒ”ãƒƒã‚¯ç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
@app.get("/")
async def root():
    return {"message": "Crypto Article Generation System API", "status": "running"}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

# ãƒˆãƒ”ãƒƒã‚¯é–¢é€£ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/api/topics")
async def get_topics(
    limit: int = 20,
    offset: int = 0,
    priority: str = None,
    source: str = None,
    sortBy: str = None,
    force_refresh: bool = False
):
    """ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§ã‚’å–å¾—ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ï¼‰"""
    global topic_cache, last_topic_update
    
    try:
        # å¼·åˆ¶ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã¾ãŸã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒç©ºã®å ´åˆã¯æ–°ã—ã„ãƒˆãƒ”ãƒƒã‚¯ã‚’ç”Ÿæˆ
        should_refresh = (
            force_refresh or 
            not topic_cache or
            (last_topic_update and 
             (datetime.now() - last_topic_update).total_seconds() > 1800)  # 30åˆ†ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœŸé™åˆ‡ã‚Œ
        )
        
        if should_refresh and topic_generator_available:
            try:
                logger.info("ãƒˆãƒ”ãƒƒã‚¯ã‚’æ›´æ–°ä¸­...")
                # DBã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¦ãƒˆãƒ”ãƒƒã‚¯ç”Ÿæˆã«æ¸¡ã™
                db_session = next(get_db()) if auth_available else None
                new_topics = generate_topics_from_market_data(db_session)
                if db_session:
                    db_session.close()
                topic_cache = new_topics
                last_topic_update = datetime.now()
                logger.info(f"ãƒˆãƒ”ãƒƒã‚¯æ›´æ–°å®Œäº†: {len(new_topics)}ä»¶")
            except Exception as e:
                logger.error(f"ãƒˆãƒ”ãƒƒã‚¯æ›´æ–°ã«å¤±æ•—: {e}")
                # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯æ—¢å­˜ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã‚’å–å¾—
        available_topics = topic_cache if topic_cache else []
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿
        if not available_topics:
            logger.warning("å®Ÿãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            available_topics = [
                {
                    "id": "fallback_1",
                    "title": "ğŸ” ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¸‚å ´ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...",
                    "priority": "medium",
                    "score": 50,
                    "coins": ["BTC"],
                    "collectedAt": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "source": "ã‚·ã‚¹ãƒ†ãƒ ",
                    "summary": "ç¾åœ¨ã€æœ€æ–°ã®å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ã„ã¾ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚",
                    "type": "system",
                    "estimatedReadTime": 3
                }
            ]
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_topics = available_topics
        
        if priority:
            filtered_topics = [t for t in filtered_topics if t.get("priority") == priority]
        
        if source:
            filtered_topics = [t for t in filtered_topics if source.lower() in t.get("source", "").lower()]
        
        # ã‚½ãƒ¼ãƒˆ
        if sortBy == "created_at":
            filtered_topics = sorted(filtered_topics, key=lambda x: x.get("collectedAt", ""), reverse=True)
        elif sortBy == "score":
            filtered_topics = sorted(filtered_topics, key=lambda x: x.get("score", 0), reverse=True)
        
        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
        total_count = len(filtered_topics)
        start_idx = offset
        end_idx = min(offset + limit, total_count)
        topics_page = filtered_topics[start_idx:end_idx]
        
        return {
            "topics": topics_page,
            "pagination": {
                "total": total_count,
                "offset": offset,
                "limit": limit,
                "hasMore": end_idx < total_count
            }
        }
        
    except Exception as e:
        logger.error(f"Error getting topics: {e}")
        return JSONResponse(
            status_code=500,
            content={"detail": f"ãƒˆãƒ”ãƒƒã‚¯ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"}
        )

# AIè¨˜äº‹ç”Ÿæˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰
@app.post("/api/articles/generate")
async def generate_article(request: Request):
    """AIè¨˜äº‹ç”Ÿæˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ - é«˜å“è³ªãªåˆ†æè¨˜äº‹ã‚’ç”Ÿæˆ"""
    try:
        body = await request.json()
        topic_id = body.get('topicId')
        topic_title = body.get('topicTitle', 'Sample Topic')
        topic_type = body.get('topicType', 'analysis')
        coins = body.get('coins', [])
        primary_data = body.get('primaryData', {})
        generation_settings = body.get('settings', {})
        
        # è¨˜äº‹ç”Ÿæˆã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆ
        article_content = await generate_ai_content(
            topic_title=topic_title,
            topic_type=topic_type,
            coins=coins,
            primary_data=primary_data,
            settings=generation_settings
        )
        
        # è¨˜äº‹å“è³ªã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        quality_score = calculate_article_quality(article_content)
        
        # è¨˜äº‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        generated_article = {
            "id": f"article_{topic_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "title": article_content["title"],
            "content": article_content["content"],
            "summary": article_content["summary"],
            "type": topic_type,
            "status": "draft",
            "wordCount": len(article_content["content"].split()),
            "generatedAt": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "estimatedReadTime": max(1, len(article_content["content"].split()) // 200),
            "topic_id": topic_id,
            "coins": coins,
            "qualityScore": quality_score,
            "seoKeywords": article_content.get("keywords", []),
            "tags": article_content.get("tags", []),
            "generationMethod": article_content.get("method", "AI"),
            "confidence": article_content.get("confidence", 0.85)
        }
        
        return {
            "success": True,
            "article": generated_article,
            "message": "è¨˜äº‹ãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚Œã¾ã—ãŸ",
            "metadata": {
                "qualityScore": quality_score,
                "generationTime": "~3ç§’",
                "wordCount": generated_article["wordCount"],
                "readingTime": f"{generated_article['estimatedReadTime']}åˆ†"
            }
        }
        
    except Exception as e:
        logger.error(f"Error generating article: {e}")
        return JSONResponse(
            status_code=500,
            content={"detail": f"è¨˜äº‹ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"}
        )

async def generate_ai_content(topic_title: str, topic_type: str, coins: list, primary_data: dict, settings: dict):
    """AIè¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆï¼ˆå®Ÿéš›ã®AI APIã¯ç’°å¢ƒã«å¿œã˜ã¦å®Ÿè£…ï¼‰"""
    try:
        # æš—å·é€šè²¨è¨˜äº‹ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        if topic_type == "analysis":
            content_template = f"""
# {topic_title}

## è¦ç´„
{topic_title}ã«ã¤ã„ã¦ã€æœ€æ–°ã®å¸‚å ´å‹•å‘ã¨åˆ†æçµæœã‚’ãŠä¼ãˆã—ã¾ã™ã€‚

## å¸‚å ´æ¦‚æ³
é–¢é€£ã™ã‚‹æš—å·é€šè²¨: {', '.join(coins) if coins else 'BTC, ETH'}

{f"ç¾åœ¨ä¾¡æ ¼: ${primary_data.get('currentPrice', 'N/A')}" if primary_data.get('currentPrice') else ""}
{f"24æ™‚é–“å¤‰å‹•: {primary_data.get('change24h', 'N/A')}%" if primary_data.get('change24h') else ""}
{f"å–å¼•é«˜: {primary_data.get('volume24h', 'N/A')}" if primary_data.get('volume24h') else ""}

## è©³ç´°åˆ†æ

### æŠ€è¡“çš„æŒ‡æ¨™
ç¾åœ¨ã®å¸‚å ´çŠ¶æ³ã‚’åˆ†æã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªå‚¾å‘ãŒè¦‹ã‚‰ã‚Œã¾ã™ï¼š

- **ä¾¡æ ¼å‹•å‘**: ä¸­æœŸçš„ãªãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
- **å‡ºæ¥é«˜**: å¸‚å ´å‚åŠ è€…ã®æ´»å‹•ãƒ¬ãƒ™ãƒ«
- **æ”¯æŒãƒ»æŠµæŠ—ãƒ¬ãƒ™ãƒ«**: ã‚­ãƒ¼ã¨ãªã‚‹ä¾¡æ ¼å¸¯

### ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«è¦å› 
å¸‚å ´ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ä¸»è¦ãªè¦å› ï¼š

1. **è¦åˆ¶ç’°å¢ƒã®å¤‰åŒ–**
2. **æ©Ÿé–¢æŠ•è³‡å®¶ã®å‹•å‘**
3. **æŠ€è¡“é–‹ç™ºã®é€²å±•**
4. **ãƒã‚¯ãƒ­çµŒæ¸ˆæƒ…å‹¢**

### ãƒªã‚¹ã‚¯è©•ä¾¡
æŠ•è³‡ã‚’æ¤œè¨ã™ã‚‹éš›ã®æ³¨æ„ç‚¹ï¼š

- **å¸‚å ´ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£**: ä¾¡æ ¼å¤‰å‹•ã®å¤§ãã•
- **æµå‹•æ€§ãƒªã‚¹ã‚¯**: å–å¼•ã®ã—ã‚„ã™ã•
- **è¦åˆ¶ãƒªã‚¹ã‚¯**: æ³•çš„ãªä¸ç¢ºå®Ÿæ€§

## ä»Šå¾Œã®å±•æœ›

### çŸ­æœŸäºˆæ¸¬ï¼ˆ1-3ãƒ¶æœˆï¼‰
æŠ€è¡“çš„åˆ†æã«åŸºã¥ãçŸ­æœŸçš„ãªè¦‹é€šã—

### ä¸­é•·æœŸäºˆæ¸¬ï¼ˆ6-12ãƒ¶æœˆï¼‰
ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«è¦å› ã‚’è€ƒæ…®ã—ãŸä¸­é•·æœŸå±•æœ›

## ã¾ã¨ã‚
{topic_title}ã«é–¢ã™ã‚‹åˆ†æã‚’ã¾ã¨ã‚ã‚‹ã¨ã€æŠ•è³‡å®¶ã«ã¨ã£ã¦é‡è¦ãªåˆ¤æ–­ææ–™ã¨ãªã‚‹è¤‡æ•°ã®è¦å› ãŒç¢ºèªã•ã‚Œã¦ã„ã¾ã™ã€‚å¸‚å ´ã®å‹•å‘ã‚’æ³¨æ„æ·±ãç›£è¦–ã—ã€ãƒªã‚¹ã‚¯ç®¡ç†ã‚’é©åˆ‡ã«è¡Œã†ã“ã¨ãŒé‡è¦ã§ã™ã€‚

---
*æœ¬è¨˜äº‹ã¯å¸‚å ´åˆ†æã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€æŠ•è³‡åŠ©è¨€ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚æŠ•è³‡åˆ¤æ–­ã¯è‡ªå·±è²¬ä»»ã§è¡Œã£ã¦ãã ã•ã„ã€‚*
"""
        else:
            # ä»–ã®ã‚¿ã‚¤ãƒ—ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
            content_template = f"""
# {topic_title}

## æ¦‚è¦
{topic_title}ã«ã¤ã„ã¦ã€æœ€æ–°ã®æƒ…å ±ã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚

## è©³ç´°å†…å®¹
æš—å·é€šè²¨å¸‚å ´ã«ãŠã‘ã‚‹é‡è¦ãªå‹•å‘ã¨ã—ã¦ã€{topic_title}ãŒæ³¨ç›®ã‚’é›†ã‚ã¦ã„ã¾ã™ã€‚

### ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ
1. å¸‚å ´ã®ç¾çŠ¶
2. æ³¨ç›®ã™ã¹ãè¦å› 
3. ä»Šå¾Œã®å±•æœ›

## ã¾ã¨ã‚
{topic_title}ã¯æš—å·é€šè²¨ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦é‡è¦ãªæ„å‘³ã‚’æŒã¤ãƒˆãƒ”ãƒƒã‚¯ã§ã™ã€‚
"""

        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªå‘ä¸Šã®ãŸã‚ã®è¿½åŠ å‡¦ç†
        enhanced_content = enhance_article_content(content_template, coins, primary_data)
        
        return {
            "title": f"{topic_title} - è©³ç´°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ",
            "content": enhanced_content,
            "summary": f"{topic_title}ã®æœ€æ–°åˆ†æã€‚å¸‚å ´å‹•å‘ã€æŠ€è¡“æŒ‡æ¨™ã€ãƒªã‚¹ã‚¯è©•ä¾¡ã‚’å«ã‚€åŒ…æ‹¬çš„ãªãƒ¬ãƒãƒ¼ãƒˆã€‚",
            "keywords": extract_keywords(topic_title, coins),
            "tags": generate_tags(topic_type, coins),
            "method": "AI Enhanced Template",
            "confidence": 0.87
        }
        
    except Exception as e:
        logger.error(f"Error in AI content generation: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚·ãƒ³ãƒ—ãƒ«ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        return {
            "title": f"{topic_title} - åˆ†æè¨˜äº‹",
            "content": f"## {topic_title}\n\n{topic_title}ã«ã¤ã„ã¦åˆ†æã‚’è¡Œã„ã¾ã—ãŸã€‚\n\nè©³ç´°ãªå¸‚å ´å‹•å‘ã¨ä»Šå¾Œã®å±•æœ›ã‚’ãŠä¼ãˆã—ã¾ã™ã€‚",
            "summary": f"{topic_title}ã®åˆ†æè¨˜äº‹",
            "keywords": [topic_title] + coins,
            "tags": [topic_type],
            "method": "Fallback Template",
            "confidence": 0.70
        }

def enhance_article_content(content: str, coins: list, primary_data: dict) -> str:
    """è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å“è³ªå‘ä¸Š"""
    enhanced = content
    
    # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®è¿½åŠ æƒ…å ±
    if primary_data.get('currentPrice'):
        price_analysis = f"\n### ä¾¡æ ¼åˆ†æ\nç¾åœ¨ä¾¡æ ¼ ${primary_data['currentPrice']:,} ã¯ã€"
        if primary_data.get('change24h', 0) > 5:
            price_analysis += "å¼·ã„ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚"
        elif primary_data.get('change24h', 0) < -5:
            price_analysis += "èª¿æ•´å±€é¢ã«ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚"
        else:
            price_analysis += "æ¯”è¼ƒçš„å®‰å®šã—ãŸæ¨ç§»ã‚’è¦‹ã›ã¦ã„ã¾ã™ã€‚"
        
        enhanced = enhanced.replace("## ã¾ã¨ã‚", price_analysis + "\n\n## ã¾ã¨ã‚")
    
    return enhanced

def extract_keywords(topic_title: str, coins: list) -> list:
    """SEOã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º"""
    base_keywords = ["æš—å·é€šè²¨", "ä»®æƒ³é€šè²¨", "ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³", "æŠ•è³‡", "åˆ†æ"]
    topic_keywords = topic_title.split()
    return list(set(base_keywords + topic_keywords + coins))[:10]

def generate_tags(topic_type: str, coins: list) -> list:
    """è¨˜äº‹ã‚¿ã‚°ç”Ÿæˆ"""
    base_tags = [topic_type, "å¸‚å ´åˆ†æ", "æš—å·é€šè²¨"]
    return list(set(base_tags + coins))[:8]

def calculate_article_quality(content: dict) -> float:
    """è¨˜äº‹å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—"""
    score = 0.0
    
    # æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
    word_count = len(content["content"].split())
    if word_count > 500:
        score += 0.3
    elif word_count > 200:
        score += 0.2
    else:
        score += 0.1
    
    # æ§‹é€ ãƒã‚§ãƒƒã‚¯
    if "##" in content["content"]:
        score += 0.2
    if "###" in content["content"]:
        score += 0.1
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
    if len(content.get("keywords", [])) >= 5:
        score += 0.2
    
    # ä¿¡é ¼æ€§
    score += content.get("confidence", 0.5) * 0.2
    
    return min(1.0, score)

# ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/api/trends/analysis")
async def get_trend_analysis(
    request: Request,
    current_user: Optional[auth_models.User] = Depends(get_current_active_user) if auth_available else None
):
    """æš—å·é€šè²¨ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
    # èªè¨¼ãŒå¿…é ˆã®å ´åˆ
    if auth_available and not current_user:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="èªè¨¼ãŒå¿…è¦ã§ã™"
        )
    try:
        # ãƒ¢ãƒƒã‚¯ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯å¸‚å ´ãƒ‡ãƒ¼ã‚¿APIã‚’ä½¿ç”¨ï¼‰
        trending_topics = [
            {
                "id": "trend_btc_surge",
                "title": "Bitcoinä¾¡æ ¼ãŒæ€¥é¨°ã€æ©Ÿé–¢æŠ•è³‡å®¶ã®è²·ã„ãŒåŠ é€Ÿ",
                "trend_type": "price_movement",
                "coins": ["BTC"],
                "confidence": 0.92,
                "sentiment": "bullish",
                "volume_spike": 45.6,
                "trending_score": 95,
                "time_frame": "24h",
                "key_factors": [
                    "ETFæ‰¿èªã¸ã®æœŸå¾…",
                    "æ©Ÿé–¢æŠ•è³‡å®¶ã®å‚å…¥",
                    "ãƒã‚¯ãƒ­çµŒæ¸ˆç’°å¢ƒã®æ”¹å–„"
                ],
                "potential_impact": "é«˜",
                "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            },
            {
                "id": "trend_defi_growth",
                "title": "DeFiãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®TVLæ€¥å¢—ã€æ–°ãŸãªé‡‘èé©å‘½ã®å…†ã—",
                "trend_type": "sector_growth",
                "coins": ["ETH", "UNI", "AAVE"],
                "confidence": 0.88,
                "sentiment": "positive",
                "volume_spike": 23.4,
                "trending_score": 87,
                "time_frame": "7d",
                "key_factors": [
                    "æ–°ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®ãƒ­ãƒ¼ãƒ³ãƒ",
                    "åˆ©å›ã‚Šè¾²æ¥­ã®é€²åŒ–",
                    "è¦åˆ¶ç’°å¢ƒã®æ˜ç¢ºåŒ–"
                ],
                "potential_impact": "ä¸­-é«˜",
                "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            },
            {
                "id": "trend_regulatory_update",
                "title": "ä¸»è¦å›½ã§ã®æš—å·é€šè²¨è¦åˆ¶ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ç­–å®š",
                "trend_type": "regulatory",
                "coins": ["BTC", "ETH", "BNB"],
                "confidence": 0.83,
                "sentiment": "neutral",
                "volume_spike": 12.8,
                "trending_score": 79,
                "time_frame": "30d",
                "key_factors": [
                    "G20è«¸å›½ã®å”èª¿",
                    "CBDCé–‹ç™ºã®åŠ é€Ÿ",
                    "ç¨åˆ¶ã®æ˜ç¢ºåŒ–"
                ],
                "potential_impact": "é«˜",
                "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        ]
        
        return {
            "success": True,
            "trends": trending_topics,
            "metadata": {
                "total_trends": len(trending_topics),
                "analysis_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "data_sources": ["Market Data", "Social Sentiment", "News Analysis"],
                "confidence_avg": sum(t["confidence"] for t in trending_topics) / len(trending_topics)
            }
        }
        
    except Exception as e:
        logger.error(f"Error in trend analysis: {e}")
        return JSONResponse(
            status_code=500,
            content={"detail": f"ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"}
        )

@app.post("/api/trends/generate-article")
async def generate_trend_article(
    request: Request,
    current_user: Optional[auth_models.User] = Depends(get_current_active_user) if auth_available else None
):
    """ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ™ãƒ¼ã‚¹ã®è¨˜äº‹è‡ªå‹•ç”Ÿæˆ"""
    # èªè¨¼ãŒå¿…é ˆã®å ´åˆ
    if auth_available and not current_user:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="èªè¨¼ãŒå¿…è¦ã§ã™"
        )
    try:
        body = await request.json()
        trend_id = body.get('trendId')
        auto_generate = body.get('autoGenerate', True)
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’å–å¾—ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ä¸Šè¨˜ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æçµæœã‚’ä½¿ç”¨ï¼‰
        mock_trend = {
            "id": trend_id,
            "title": "Bitcoinä¾¡æ ¼ãŒæ€¥é¨°ã€æ©Ÿé–¢æŠ•è³‡å®¶ã®è²·ã„ãŒåŠ é€Ÿ",
            "coins": ["BTC"],
            "confidence": 0.92,
            "sentiment": "bullish",
            "key_factors": [
                "ETFæ‰¿èªã¸ã®æœŸå¾…",
                "æ©Ÿé–¢æŠ•è³‡å®¶ã®å‚å…¥",
                "ãƒã‚¯ãƒ­çµŒæ¸ˆç’°å¢ƒã®æ”¹å–„"
            ],
            "primary_data": {
                "currentPrice": 67420,
                "change24h": 8.5,
                "volume24h": "$28,900,000,000"
            }
        }
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’åŸºã«ã—ãŸè¨˜äº‹ç”Ÿæˆ
        article_content = await generate_trend_based_content(mock_trend)
        
        generated_article = {
            "id": f"trend_article_{trend_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "title": article_content["title"],
            "content": article_content["content"],
            "type": "trend_analysis",
            "status": "draft",
            "source": "Trend Analysis",
            "wordCount": len(article_content["content"].split()),
            "generatedAt": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "estimatedReadTime": max(1, len(article_content["content"].split()) // 200),
            "trendId": trend_id,
            "coins": mock_trend["coins"],
            "confidence": mock_trend["confidence"],
            "sentiment": mock_trend["sentiment"],
            "autoGenerated": auto_generate,
            "qualityScore": calculate_article_quality(article_content)
        }
        
        return {
            "success": True,
            "article": generated_article,
            "trend_data": mock_trend,
            "message": "ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ™ãƒ¼ã‚¹è¨˜äº‹ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ"
        }
        
    except Exception as e:
        logger.error(f"Error generating trend article: {e}")
        return JSONResponse(
            status_code=500,
            content={"detail": f"ãƒˆãƒ¬ãƒ³ãƒ‰è¨˜äº‹ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"}
        )

def get_sentiment_description(sentiment: str) -> str:
    """ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã®èª¬æ˜ã‚’å–å¾—"""
    descriptions = {
        "bullish": "å¼·æ°—ã«å‚¾ã„ã¦ã„ã¾ã™",
        "bearish": "å¼±æ°—ã«è»¢ã˜ã¦ã„ã¾ã™", 
        "neutral": "ä¸­ç«‹çš„ãªçŠ¶æ³ã§ã™",
        "positive": "ãƒã‚¸ãƒ†ã‚£ãƒ–ã«æ¨ç§»ã—ã¦ã„ã¾ã™"
    }
    return descriptions.get(sentiment, "å¤‰åŒ–ã—ã¦ã„ã¾ã™")

async def generate_trend_based_content(trend_data: dict):
    """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã«åŸºã¥ãè¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ"""
    title = trend_data["title"]
    coins = trend_data["coins"]
    sentiment = trend_data["sentiment"]
    key_factors = trend_data.get("key_factors", [])
    primary_data = trend_data.get("primary_data", {})
    
    sentiment_emoji = {
        "bullish": "ğŸš€",
        "bearish": "ğŸ“‰", 
        "neutral": "â¡ï¸",
        "positive": "ğŸ“ˆ"
    }.get(sentiment, "ğŸ“Š")
    
    content = f"""
# {sentiment_emoji} {title}

## ãƒˆãƒ¬ãƒ³ãƒ‰æ¦‚è¦
ç¾åœ¨ã®å¸‚å ´å‹•å‘ã¨ã—ã¦ã€{title.lower()}ã¨ã„ã†é‡è¦ãªå¤‰åŒ–ãŒè¦³æ¸¬ã•ã‚Œã¦ã„ã¾ã™ã€‚
é–¢é€£ã™ã‚‹æš—å·é€šè²¨: **{', '.join(coins)}**

### å¸‚å ´ãƒ‡ãƒ¼ã‚¿
{f"- ç¾åœ¨ä¾¡æ ¼: **${primary_data.get('currentPrice', 'N/A'):,}**" if primary_data.get('currentPrice') else ""}
{f"- 24æ™‚é–“å¤‰å‹•: **{primary_data.get('change24h', 'N/A')}%**" if primary_data.get('change24h') else ""}
{f"- å–å¼•é«˜: **{primary_data.get('volume24h', 'N/A')}**" if primary_data.get('volume24h') else ""}

## ä¸»è¦ãªå½±éŸ¿è¦å› 

ã“ã®å¸‚å ´å‹•å‘ã®èƒŒæ™¯ã«ã¯ã€ä»¥ä¸‹ã®è¦å› ãŒç¢ºèªã•ã‚Œã¦ã„ã¾ã™ï¼š

{chr(10).join(f"{i+1}. **{factor}**" for i, factor in enumerate(key_factors))}

## è©³ç´°åˆ†æ

### å¸‚å ´ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ
ç¾åœ¨ã®å¸‚å ´ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã¯**{sentiment}**ã¨ãªã£ã¦ãŠã‚Šã€æŠ•è³‡å®¶ã®å¿ƒç†ãŒ{get_sentiment_description(sentiment)}ã€‚

### æŠ€è¡“çš„åˆ†æ
- **ã‚µãƒãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«**: é‡è¦ãªæ”¯æŒç·šã®ç¢ºèª
- **ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«**: ä¸Šå€¤æŠµæŠ—ç·šã®çŠ¶æ³
- **å‡ºæ¥é«˜åˆ†æ**: å–å¼•é‡ã®å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³

### å½±éŸ¿äºˆæ¸¬
ã“ã®å‹•å‘ãŒç¶™ç¶šã—ãŸå ´åˆã®äºˆæƒ³ã•ã‚Œã‚‹å½±éŸ¿ï¼š

- **çŸ­æœŸçš„å½±éŸ¿ï¼ˆ1-7æ—¥ï¼‰**: ä¾¡æ ¼ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®ç¶™ç¶š
- **ä¸­æœŸçš„å½±éŸ¿ï¼ˆ1-4é€±é–“ï¼‰**: ãƒˆãƒ¬ãƒ³ãƒ‰ã®å®šç€ã¾ãŸã¯åè»¢
- **é•·æœŸçš„å½±éŸ¿ï¼ˆ1-3ãƒ¶æœˆï¼‰**: å¸‚å ´æ§‹é€ ã®å¤‰åŒ–

## æŠ•è³‡å®¶ã¸ã®ç¤ºå”†

### ãƒªã‚¹ã‚¯è¦å› 
- å¸‚å ´ã®æ€¥æ¿€ãªå¤‰å‹•å¯èƒ½æ€§
- å¤–éƒ¨è¦å› ã«ã‚ˆã‚‹å½±éŸ¿
- æµå‹•æ€§ã®å¤‰åŒ–

### æ©Ÿä¼šè¦å›   
- æ–°ãŸãªæˆé•·ã‚»ã‚¯ã‚¿ãƒ¼ã¸ã®å‚å…¥æ©Ÿä¼š
- ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå¤šæ§˜åŒ–ã®æ¤œè¨
- é•·æœŸæŠ•è³‡æˆ¦ç•¥ã®è¦‹ç›´ã—

## ã¾ã¨ã‚

{title}ã¯æš—å·é€šè²¨å¸‚å ´ã«ãŠã„ã¦æ³¨ç›®ã™ã¹ãé‡è¦ãªå‹•å‘ã§ã™ã€‚æŠ•è³‡å®¶ã¯å¸‚å ´ã®å¤‰åŒ–ã‚’æ³¨æ„æ·±ãç›£è¦–ã—ã€ãƒªã‚¹ã‚¯ç®¡ç†ã‚’é©åˆ‡ã«è¡Œã„ãªãŒã‚‰ã€æ©Ÿä¼šã‚’æ‰ãˆã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚

---
*æœ¬è¨˜äº‹ã¯ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã«åŸºã¥ãæƒ…å ±æä¾›ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€æŠ•è³‡åŠ©è¨€ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚*
"""

    return {
        "title": f"{sentiment_emoji} {title} - ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æãƒ¬ãƒãƒ¼ãƒˆ",
        "content": content,
        "summary": f"{title}ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã€‚å¸‚å ´å‹•å‘ã€å½±éŸ¿è¦å› ã€æŠ•è³‡ã¸ã®ç¤ºå”†ã‚’å«ã‚€åŒ…æ‹¬çš„ãªãƒ¬ãƒãƒ¼ãƒˆã€‚",
        "keywords": extract_keywords(title, coins) + ["ãƒˆãƒ¬ãƒ³ãƒ‰", "å¸‚å ´åˆ†æ"],
        "tags": ["trend_analysis", sentiment] + coins,
        "confidence": trend_data.get("confidence", 0.85)
    }

# è¨˜äº‹é–¢é€£ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/api/articles")
async def get_articles(
    limit: int = 20,
    offset: int = 0,
    status: str = None,
    type: str = None,
    search: str = None
):
    """è¨˜äº‹ä¸€è¦§ã‚’å–å¾—ï¼ˆãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ï¼‰"""
    try:
        # ãƒ¢ãƒƒã‚¯è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        mock_articles = [
            {
                "id": "article_1",
                "title": "Bitcoinä¾¡æ ¼åˆ†æï¼šæ–°ãŸãªå¼·æ°—ç›¸å ´ã®å§‹ã¾ã‚Šã‹ï¼Ÿ",
                "type": "analysis",
                "wordCount": 1250,
                "status": "published",
                "generatedAt": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "coins": ["BTC"],
                "source": "AIç”Ÿæˆ",
                "sourceUrl": None,
                "content": "Bitcoinï¼ˆBTCï¼‰ã¯éå»24æ™‚é–“ã§å¤§å¹…ãªä¾¡æ ¼ä¸Šæ˜‡ã‚’è¨˜éŒ²ã—ã€å¸‚å ´å‚åŠ è€…ã®æ³¨ç›®ã‚’é›†ã‚ã¦ã„ã¾ã™...",
                "summary": "Bitcoinã®æœ€æ–°ä¾¡æ ¼å‹•å‘ã¨ä»Šå¾Œã®å±•æœ›ã«ã¤ã„ã¦è©³ç´°åˆ†æ"
            },
            {
                "id": "article_2",
                "title": "Ethereum 2.0ã®ã‚¹ãƒ†ãƒ¼ã‚­ãƒ³ã‚°ç’°å¢ƒå¤‰åŒ–ãŒå¸‚å ´ã«ä¸ãˆã‚‹å½±éŸ¿",
                "type": "technical",
                "wordCount": 980,
                "status": "draft",
                "generatedAt": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "coins": ["ETH"],
                "source": "AIç”Ÿæˆ",
                "sourceUrl": None,
                "content": "Ethereum 2.0ã«ãŠã‘ã‚‹ã‚¹ãƒ†ãƒ¼ã‚­ãƒ³ã‚°å ±é…¬ç‡ã®å¤‰åŒ–ã¯ã€é•·æœŸçš„ãªãƒ›ãƒ«ãƒ€ãƒ¼ã®æˆ¦ç•¥ã«å¤§ããªå½±éŸ¿ã‚’ä¸ãˆã¦ã„ã¾ã™...",
                "summary": "ETH2.0ã‚¹ãƒ†ãƒ¼ã‚­ãƒ³ã‚°ã®æœ€æ–°å‹•å‘ã¨ãã®å¸‚å ´ã¸ã®å½±éŸ¿"
            },
            {
                "id": "article_3",
                "title": "DeFiãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®æ–°ãŸãªé€²åŒ–ï¼šSolanaã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã®æˆé•·",
                "type": "news",
                "wordCount": 750,
                "status": "published",
                "generatedAt": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "coins": ["SOL"],
                "source": "AIç”Ÿæˆ",
                "sourceUrl": None,
                "content": "Solanaï¼ˆSOLï¼‰ã®DeFiã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã¯è¿‘æ—¥ä¸­ã«è¤‡æ•°ã®é‡è¦ãªã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã‚’è¿ãˆã¾ã™...",
                "summary": "Solana DeFiã®æœ€æ–°ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¨å–å¼•é‡å¢—åŠ ã®èƒŒæ™¯"
            }
        ]
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_articles = mock_articles
        
        if status:
            filtered_articles = [a for a in filtered_articles if a["status"] == status]
        
        if type:
            filtered_articles = [a for a in filtered_articles if a["type"] == type]
        
        if search:
            search_lower = search.lower()
            filtered_articles = [
                a for a in filtered_articles 
                if search_lower in a["title"].lower() or 
                   search_lower in a["content"].lower() or
                   any(search_lower in coin.lower() for coin in a["coins"])
            ]
        
        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
        total_count = len(filtered_articles)
        start_idx = offset
        end_idx = min(offset + limit, total_count)
        articles_page = filtered_articles[start_idx:end_idx]
        
        return {
            "articles": articles_page,
            "pagination": {
                "total": total_count,
                "offset": offset,
                "limit": limit,
                "hasMore": end_idx < total_count
            }
        }
        
    except Exception as e:
        logger.error(f"Error getting articles: {e}")
        return JSONResponse(
            status_code=500,
            content={"detail": f"è¨˜äº‹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"}
        )

# ã‚·ã‚¹ãƒ†ãƒ é–¢é€£ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ  
@app.get("/api/system/stats")
async def get_system_stats(request: Request):
    """ã‚·ã‚¹ãƒ†ãƒ ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
    try:
        # åŸºæœ¬çš„ãªçµ±è¨ˆæƒ…å ±ã‚’è¿”ã™
        output_dir = "./output/articles"
        articles_today = 0
        if os.path.exists(output_dir):
            today = datetime.now().strftime("%Y%m%d")
            articles_today = len([
                f for f in os.listdir(output_dir) 
                if f.startswith(today) and f.endswith('.html')
            ])
        
        return {
            "articlesGenerated": articles_today,
            "topicsCollected": 12,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            "templatesCount": 4,    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            "systemStatus": "running",
            "lastRun": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "dailyQuota": {
                "used": articles_today,
                "total": 50
            },
            "scheduler": {
                "isRunning": True,
                "isCollecting": False,
                "lastCollectionTime": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "collectionCount": 5,
                "errorCount": 0,
                "nextRunTime": "Next run in 15 minutes"
            }
        }
    except Exception as e:
        logger.error(f"Error getting system stats: {e}")
        return JSONResponse(
            status_code=500, 
            content={"detail": f"ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"}
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)